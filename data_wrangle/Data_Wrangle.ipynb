{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import re\n",
    "import io\n",
    "import urllib\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Clean Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using http://www.trumptwitterarchive.com/archive , I downloaded all of Donald Trump's tweets from 01/01/2016 - 10/11/2017 9:19 am MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepath to twitter archive data.\n",
    "twitter_json = r'C:\\Users\\aregel\\Documents\\springboard\\Capstone_2\\data_wrangle\\data\\twitter_01_01_16_to_10-11-17.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas I will read the twitter json file, convert it to a dataframe, set the index to 'created at' as datetime objects, then write it to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the json data into a pandas dataframe\n",
    "tweet_data = pd.read_json(twitter_json)\n",
    "# set column 'created_at' to the index\n",
    "tweet_data.set_index('created_at', drop=True, inplace= True)\n",
    "# convert timestamp index to a datetime index\n",
    "pd.to_datetime(tweet_data.index)\n",
    "# write to csv file\n",
    "csv_file_path = r'C:\\Users\\aregel\\Documents\\springboard\\Capstone_2\\data_wrangle\\data\\twitter_01_01_16_to_10-11-17.csv' \n",
    "tweet_data.to_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scrape Data from the Federal Register\n",
    "## This has already been done, and all of the pdfs published by the Executive Office of the U.S.A are in the data folder from 2016/01/01 - 2017/10/15\n",
    "\n",
    "## *Don't execute this code unless you need more up-to-date information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the 2016, 2017 url that contains all of the Executive Office of the President's published documents\n",
    "executive_office_url_2016 = r'https://www.federalregister.gov/index/2016/executive-office-of-the-president'\n",
    "executive_office_url_2017 = r'https://www.federalregister.gov/index/2017/executive-office-of-the-president' \n",
    "\n",
    "# scrape all urls for pdf documents published 2016-01-01 to 2017-10-15 by the U.S.A. Executive Office\n",
    "pdf_urls= []\n",
    "for url in [executive_office_url_2016, executive_office_url_2017]:\n",
    "    response = requests.get(url)\n",
    "    pattern = re.compile(r'https:.*\\.pdf')\n",
    "    pdfs = re.findall(pattern, response.text)\n",
    "    pdf_urls.append(pdfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writes all of the pdfs to the data folder\n",
    "start = 'data/'\n",
    "end = '.pdf'\n",
    "num = 0\n",
    "for i in range(0,(len(pdf_urls))):\n",
    "    for url in pdf_urls[i]:\n",
    "        ver = str(num)\n",
    "        pdf_path = start + ver + end\n",
    "        pdfFile = urllib.request.urlopen(url)\n",
    "        file = open(pdf_path, 'wb')\n",
    "        file.write(pdfFile.read())\n",
    "        file.close()\n",
    "        num = num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe with the date the pdf was published and the text of each pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to convert pdf to text from stack overflow (https://stackoverflow.com/questions/26494211/extracting-text-from-a-pdf-file-using-pdfminer-in-python/44476759#44476759)\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "# finds the first time a day appears in the txt, and returns that day\n",
    "def find_day(word_generator):\n",
    "    day_list = ['Monday,', 'Tuesday,', 'Wednesday,', 'Thursday,', 'Friday,', 'Saturday,', 'Sunday,']\n",
    "    day_name_dict = {'Mon':'Monday,', 'Tue':'Tuesday,','Wed':'Wednesday,','Thu':'Thursday,','Fri':'Friday,','Sat':'Saturday,','Sun':'Sunday,'}\n",
    "    day_name = []\n",
    "    for val in word_generator:\n",
    "        if val in day_list:\n",
    "            num_position = txt.index(val)\n",
    "            day_name.append(txt[num_position] + txt[num_position + 1] + txt[num_position +2])\n",
    "            break\n",
    "            \n",
    "    return day_name_dict[day_name[0]]\n",
    "# takes text and returns the first date in the document\n",
    "def extract_date(txt):\n",
    "    word_generator = (word for word in txt.split())\n",
    "    day_name = find_day(word_generator)\n",
    "    txt_start = int(txt.index(day_name))\n",
    "    txt_end = txt_start + 40\n",
    "    date_txt = txt[txt_start:txt_end].replace('\\n','')\n",
    "    cleaned_txt = re.findall('.* \\d{4}', date_txt)\n",
    "    date_list = cleaned_txt[0].split()\n",
    "    clean_date_list = map(lambda x:x.strip(\",\"), date_list)\n",
    "    clean_date_string = \", \".join(clean_date_list)\n",
    "    date_obj = datetime.strptime(clean_date_string, '%A, %B, %d, %Y')\n",
    "    return date_obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary using DefaultDict where the date of publication is the key, and the text of the pdf is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_path = r'C:/Users/aregel/Documents/springboard/Twitter-Politics/data_wrangle/data/'\n",
    "end_path = '.pdf'\n",
    "data_dict = defaultdict(list)\n",
    "for i in range(0,528):\n",
    "    file_path = start_path + str(i) + end_path\n",
    "    txt = convert_pdf_to_txt(file_path)\n",
    "    date_obj = extract_date(txt)\n",
    "    data_dict[date_obj].append(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe from the dictionary, with the key values as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_reg_dataframe = pd.DataFrame.from_dict(data_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the dataframe, so that you only need to process the text once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_reg_data = r'C:/Users/aregel/Documents/springboard/Twitter-Politics/data_wrangle/data/fed_reg_date_index.pickle'\n",
    "fed_reg_dataframe.to_pickle(fed_reg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-29</th>\n",
       "      <td>Federal  Register / Vol.  81,  No.  39 / Monda...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-21</th>\n",
       "      <td>Federal  Register / Vol.  81,  No.  77 / Thurs...</td>\n",
       "      <td>Federal  Register / Vol.  81,  No.  77 / Thurs...</td>\n",
       "      <td>Vol. 81 \\nNo. 77 \\n\\nThursday, \\nApril 21, 201...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>Federal  Register / Vol.  81,  No.  71 / Wedne...</td>\n",
       "      <td>Vol. 81 \\nNo. 71 \\n\\nWednesday, \\nApril 13, 20...</td>\n",
       "      <td>Federal  Register / Vol.  81,  No.  71 / Wedne...</td>\n",
       "      <td>Federal  Register / Vol.  81,  No.  71 / Wedne...</td>\n",
       "      <td>Federal  Register / Vol.  81,  No.  71 / Wedne...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-26</th>\n",
       "      <td>Federal  Register \\n\\nVol.  81,  No.  166 \\n\\n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-23</th>\n",
       "      <td>Federal  Register / Vol.  81,  No.  99 / Monda...</td>\n",
       "      <td>Vol. 81 \\nNo. 99 \\n\\nMonday, \\nMay 23, 2016 \\n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0   \\\n",
       "2016-02-29  Federal  Register / Vol.  81,  No.  39 / Monda...   \n",
       "2016-04-21  Federal  Register / Vol.  81,  No.  77 / Thurs...   \n",
       "2016-04-13  Federal  Register / Vol.  81,  No.  71 / Wedne...   \n",
       "2016-08-26  Federal  Register \\n\\nVol.  81,  No.  166 \\n\\n...   \n",
       "2016-05-23  Federal  Register / Vol.  81,  No.  99 / Monda...   \n",
       "\n",
       "                                                           1   \\\n",
       "2016-02-29                                               None   \n",
       "2016-04-21  Federal  Register / Vol.  81,  No.  77 / Thurs...   \n",
       "2016-04-13  Vol. 81 \\nNo. 71 \\n\\nWednesday, \\nApril 13, 20...   \n",
       "2016-08-26                                               None   \n",
       "2016-05-23  Vol. 81 \\nNo. 99 \\n\\nMonday, \\nMay 23, 2016 \\n...   \n",
       "\n",
       "                                                           2   \\\n",
       "2016-02-29                                               None   \n",
       "2016-04-21  Vol. 81 \\nNo. 77 \\n\\nThursday, \\nApril 21, 201...   \n",
       "2016-04-13  Federal  Register / Vol.  81,  No.  71 / Wedne...   \n",
       "2016-08-26                                               None   \n",
       "2016-05-23                                               None   \n",
       "\n",
       "                                                           3   \\\n",
       "2016-02-29                                               None   \n",
       "2016-04-21                                               None   \n",
       "2016-04-13  Federal  Register / Vol.  81,  No.  71 / Wedne...   \n",
       "2016-08-26                                               None   \n",
       "2016-05-23                                               None   \n",
       "\n",
       "                                                           4     5     6   \\\n",
       "2016-02-29                                               None  None  None   \n",
       "2016-04-21                                               None  None  None   \n",
       "2016-04-13  Federal  Register / Vol.  81,  No.  71 / Wedne...  None  None   \n",
       "2016-08-26                                               None  None  None   \n",
       "2016-05-23                                               None  None  None   \n",
       "\n",
       "              7     8     9     10    11    12    13    14  \n",
       "2016-02-29  None  None  None  None  None  None  None  None  \n",
       "2016-04-21  None  None  None  None  None  None  None  None  \n",
       "2016-04-13  None  None  None  None  None  None  None  None  \n",
       "2016-08-26  None  None  None  None  None  None  None  None  \n",
       "2016-05-23  None  None  None  None  None  None  None  None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
